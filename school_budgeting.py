# -*- coding: utf-8 -*-
"""school budgeting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tCf_YM0-9_7wTNeoSECA1u_a3i5F42pI

Predicting probabilities for labelling the multi-class-multi-label target variables using school data and thereby reducing the time for manually labelling the data henceforth

Importing Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.utils import shuffle
from sklearn.metrics import log_loss
from sklearn.multiclass import OneVsRestClassifier
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer
from sklearn.feature_selection import SelectKBest, chi2
# %matplotlib inline

"""Data importing and analysing"""

df=pd.read_csv('/content/drive/MyDrive/train.csv')
print(df.head())

df.drop(labels='Unnamed: 0', inplace=True, axis=1)

display(df.info())

display(df.describe())

plt.hist(df['FTE'].dropna(), bins=200)
plt.xscale(value='symlog')
plt.title('Distribution of %full-time \n employee works')
plt.xlabel('% of full-time')
plt.ylabel('num employees')
plt.show()

"""creating train and holdout datasets"""

labels = ['Function','Use', 'Sharing', 'Reporting', 'Student_Type',
          'Position_Type','Object_Type', 'Pre_K', 'Operating_Status']

def multilabel_train_test_split(data, labels, test_size=0.75):
  data=shuffle(data, random_state=8)
  labels=shuffle(labels, random_state=8)
  data=data.reset_index(drop=True)
  labels=labels.reset_index(drop=True)
  X_train = data.iloc[0: int(len(data)*test_size), :]
  X_test = data.iloc[int(len(data)*test_size):, :]
  y_train = labels.iloc[0: int(len(labels)*test_size), :]
  y_test = labels.iloc[int(len(labels)*test_size) :, :]
  return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test=multilabel_train_test_split(df.drop(labels=labels, axis=1), pd.get_dummies(data=df[labels]), test_size=0.8)

"""creating transformers for the pipeline"""

def combine_text_columns(df):
  text_data=df.drop(labels=['FTE', 'Total'], axis=1)
  text_data.fillna('', inplace=True)
  text_data=text_data.apply(lambda x: ' '.join(x), axis=1)
  return text_data

get_text_data=FunctionTransformer(combine_text_columns, validate=False)
get_numeric_data=FunctionTransformer(lambda x: x[['FTE', 'Total']], validate=False)
imputer=SimpleImputer(missing_values=np.nan, strategy='mean')
tfidf_vectorizer=TfidfVectorizer(token_pattern='[A-Za-z0-9]+(?=\\s+)' ,lowercase=True, ngram_range=(1, 2))
hash_vectorizer=HashingVectorizer(token_pattern='[A-Za-z0-9]+(?=\\s+)' ,lowercase=True, ngram_range=(1, 2), alternate_sign=False, binary=False)

"""merging the text data(selecting k best features) with numeric data and fitting the multi-class-multi-label data to Logistic regression model"""

numeric_pipeline=Pipeline([('selector', get_numeric_data),
                           ('imputer', imputer)])
text_pipeline=Pipeline([('selector', get_text_data),
                         ('vectorizer', hash_vectorizer),
                        ('dim_red', SelectKBest(chi2, 450))])
pl=Pipeline([('union', FeatureUnion([('numeric', numeric_pipeline), ('text', text_pipeline)])),
             ('scale', MaxAbsScaler()),
             ('clf', OneVsRestClassifier(LogisticRegression(max_iter=1000, n_jobs=-1)))])

pl.fit(X_train, y_train)

y_pred=np.round(pl.predict_proba(X_test),3)
loss=[]
for i in range(len(y_test.columns)):
  loss.append(log_loss(y_test.values[:,i], y_pred[:,i]))

loss=np.mean(loss)
accuracy=pl.score(X_test, y_test)
print('the accuracy of the model is {0} and log loss is {1}'.format(np.round(accuracy,2), np.round(loss,2)))

predictions=pl.predict_proba(X_test)
submission=np.round(pd.DataFrame(data=predictions, columns=y_test.columns), 3)

display(submission)